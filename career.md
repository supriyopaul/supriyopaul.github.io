### My Professional Journey

#### **Foundational Years & Early Education**

**2000 – 2011 | De Nobili School**

My academic journey began at De Nobili School, where I spent eleven years building my foundational knowledge. It was here that my natural curiosity for technology first took root. I was deeply intrigued by the dawn of the digital age, particularly **the internet and its underlying mechanisms**. This fascination led me to enroll in Computer Science classes, which provided my first formal introduction to the world of programming through the **Java** language.

* **Skills Acquired:** Foundational programming logic, introductory Java, analytical thinking.

**2011 – 2013 | DAV Public School**

Continuing my education at DAV Public School, I naturally opted for Computer Science to delve deeper into my passion. This period was instrumental in broadening my technical horizons, as I learned additional programming languages, including **C++ and PHP**, becoming significantly more tech-savvy. Beyond the curriculum, I was captivated by the burgeoning smartphone ecosystem and spent countless hours on the **XDA Developers forums**. This hands-on exploration involved experimenting with custom firmware, software modifications, and troubleshooting complex technical issues, which sharpened my practical problem-solving skills. It was during this time that I solidified my ambition to pursue **Computer Science as a professional career**, with my passion for football serving as a cherished Plan B.

* **Skills Acquired:** C++, PHP, advanced programming concepts, practical troubleshooting, self-directed learning, mobile operating system fundamentals.

#### **Higher Education & Specialization**

**2013 – 2017 | Bachelor of Engineering in Computer Science & Engineering**

I chose to major in Computer Science and Engineering, pursuing my degree from **Mallabhum Institute of Technology**. This was a decision I was committed to, even though it was unconventional within my family at the time. My college years were a period of immense learning, where I was formally introduced to the core principles that govern the digital world. The curriculum covered a wide spectrum of essential topics, including **16-bit microprocessors, Computer Architecture, the Linux kernel, and intricate Networks and protocols**. This comprehensive education provided me with a robust understanding of how software and hardware interact.

Outside of academics, I also discovered a passion for volleyball, where I honed my skills in teamwork, strategy, and coordination, eventually becoming a proficient player.

* **Skills Acquired:** Core Computer Science fundamentals (Data Structures, Algorithms, OS), understanding of computer architecture and networking, Linux kernel basics, teamwork, and collaboration.

---

### **Professional Experience**

#### **Associate Software Engineer at Deepcompute**

**2017 – 2019**

My professional career began at **Deepcompute**, a dynamic startup that served as the primary technology backend for nference. Nference's platform was designed to accelerate **drug discovery and development by analyzing and organizing vast datasets** scraped from medical literature, Wikipedia, FDA databases, and clinical trials. For its clients, including major pharmaceutical corporations like Johnson & Johnson, Pfizer, and Merck, the platform produced powerful insights through tools like **gene-drug relationship heatmaps and trend analysis charts**.

In this role, I transitioned from Java to **Python** and was tasked with building and supporting critical internal tools. I actively **collaborated with cross-functional teams to develop and enhance several open-source libraries** and modules like `logagg`, `basescript`, and `deeputil`. My primary responsibilities revolved around the data pipeline, which involved ingesting large volumes of JSON data and administering the supporting infrastructure, including **MongoDB**, **InfluxDB**, and **NSQ**.

Beyond tool development, I played a pivotal role in shaping our engineering practices by facilitating deployments using **Docker and Travis CI**. This role solidified my belief in robust engineering; I became a **passionate advocate for clean, maintainable code**, especially after implementing CI/CD checks and using tools like `doctest` to enforce quality and documentation simultaneously. After my first year, I also briefly ventured into creative design, making and selling stickers.

* **Key Skills:** Python, **Data Pipelines**, **NSQ**, **MongoDB**, **InfluxDB**, Docker, **CI/CD Pipeline Management**, Bash Scripting, Git Workflows, Linux System Administration, Open-Source Contribution.

#### **DevOps Engineer at Ajio (Reliance)**

**2019 – 2021**

I moved to Ajio, where I **founded and led the Tools & Automation team**. My mission was to implement strategic automation solutions that would streamline workflows and eliminate redundant tasks across the organization. This was a critical period, as Ajio was undergoing a massive migration to a microservices architecture.

Before building the large-scale ELK pipeline, my initial focus was on operational stability, where I implemented **Prometheus** for monitoring and alerting on ad-hoc internal tasks. My team's flagship project became a **centralized visibility platform** built on **ELK and Kafka clusters**, designed to pinpoint performance bottlenecks in real-time. We scaled this platform to support over **16 microservices**, processing over **7 billion log records daily**. I was responsible for the architecture, scalability, and optimization of these clusters, as well as leading the infrastructure benchmarking for migration to Jio’s in-house cloud, “JAWS”. All deployments and configuration changes were managed using **Ansible**.

* **Key Skills:** **ELK Stack Administration**, **Apache Kafka Management**, **Prometheus**, Large-Scale Data Architecture, System Scalability & Performance Tuning, **Ansible**, Microservices Monitoring, Team Leadership.

#### **Software Engineer at Jio (AI-Center of Excellence)**

**2021 – 2023**

I transitioned to the AI-Center of Excellence (AI-COE) team at Jio. The team's vision was to build a unified **ML and MLOps platform** to standardize pipelines for data ingestion, model training, and inference. To ground myself in the team's domain upon joining, I completed the **[AI for Everyone](https://www.coursera.org/account/accomplishments/certificate/JMQWSQBKDSZC)** course.

My primary contribution was engineering a comprehensive **Knowledge Graph platform** built on **ArangoDB**, using **Redis** for caching to enhance query performance. The platform's microservices architecture was built on **gRPC and Protocol Buffers**, for which I earned a specialized **[certification](https://www.udemy.com/certificate/UC-1dd3f3c2-d8ad-46b5-9a09-801f26cf0df6/)**. As the team grew, my role evolved to include mentoring and training new members. Beyond leadership, I also **spearheaded the performance monitoring, scaling, and refinement of our Knowledge Graph services**, ensuring high reliability and efficiency. The entire platform was deployed on **Kubernetes** using CI/CD pipelines I built on **Azure DevOps**.

* **Key Skills:** System Design & Architecture, **gRPC**, **ArangoDB**, **Redis**, **Kubernetes**, **Azure DevOps**, MLOps, Technical Leadership & Mentorship.

---

### **Personal Growth & Projects**

**2023 – 2024**

To continuously sharpen my foundational skills, I dedicated time to competitive programming. To prepare, I took a dedicated course on **Data Structures & Algorithms** and also completed a comprehensive **[System Design certification](https://www.udemy.com/certificate/UC-a6688b24-e5c2-48e2-9c10-231f972eae68/)**. This preparation culminated in a **[50-day challenge on LeetCode](https://drive.google.com/file/d/1zZOSrQ-3x5oreK_nLA0wplgx-I7muvmc/view?usp=sharing)**, where I earned a badge awarded to the **top 6.9% of global participants**.

Fueled by my experience across diverse teams and my ambition as an **aspiring system architect**, I sought a role with greater end-to-end ownership. To aid my job search, I built **`applibot.io`**, a **RAG application** to automate job applications. The tech stack included **LanceDB**, **PostgreSQL**, **FastAPI**, and I leveraged **LangChain** alongside OpenAI models as the primary LLM framework.

* **Key Skills:** **RAG Architecture**, **LLMs**, **LangChain**, **Vector Databases**, FastAPI, Full-Stack Development, Product Ideation.

#### **Software Engineer at H&M (PLM & Hub Team)**

**2024 – Present**

Using `applibot`, I secured my current role at H&M. I work on the central Hub, a platform that acts as a **configurable, low-code workflow** for handling data integrations between our "Centric" PLM system and **over 10+ downstream systems**. My responsibilities include owning multiple business objects, overseeing their integrations, and maintaining our core modules and ETL pipelines on **Google Cloud Platform (GCP)**, using services like **Cloud Run, GKE, and SpannerDB**. I am deeply involved in the entire SDLC, from solution design to production support. Outside of my technical responsibilities, I'm an active part of the company culture and a keen **badminton** player, having won several internal tournaments.

* **Key Skills:** **Google Cloud Platform (GCP)**, GKE, **SpannerDB**, Python, **FastAPI**, Enterprise Integration Patterns, End-to-End SDLC Ownership.

Throughout my journey, I've balanced my deep focus in technology with a love for creative outlets. I'm an avid **anime** fan and a proficient cook. My thinking is often shaped by authors like **Yuval Noah Harari and Paulo Coelho**, whose works encourage looking at the bigger picture—a principle I apply to both my life and my work in system architecture.