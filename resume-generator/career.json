{
  "personalDetails": {
    "fullName": "Supriyo Paul",
    "currentTitle": "Senior Software Engineer",
    "brandingStatements": [
      "Software Engineer specializing in Python development, DevOps, and Automation Engineering.",
      "Currently exploring the realm of knowledge graphs and LLM frameworks.",
      "Aspiring system architect.",
      "Passionate advocate for clean, maintainable code."
    ],
    "profileImage": "https://media.licdn.com/dms/image/C4D03AQE-e0beIOvnhA/profile-displayphoto-shrink_400_400/0/1651731113597?e=1729728000&v=beta&t=M8-9g0v9F9XQ29V9bJ2W8c9Y3w4J2e8H1v5G3f7k8Xg",
    "contact": {
      "email": "paul.supriyo.paul@gmail.com",
      "phone": "+91 8340265344",
      "location": "Whitefield, Bengaluru",
      "linkedin": "https://www.linkedin.com/in/supriyopaul95",
      "github": "https://github.com/supriyopaul"
    }
  },
  "timeline": [
    {
      "id": "exp-hm-2024",
      "type": "experience",
      "heading": "Software Engineer II",
      "organization": { "name": "H&M" },
      "role": "Software Engineer II",
      "location": "Bengaluru, India",
      "startDate": "2024-03-01",
      "endDate": null,
      "narrative": "Using `applibot`, I secured my current role at H&M. I work on the central Hub, a platform that acts as a configurable, low-code workflow for handling data integrations between our 'Centric' PLM system and over 10+ downstream systems. My responsibilities include owning multiple business objects, overseeing their integrations, and maintaining our core modules and ETL pipelines on Google Cloud Platform (GCP), using services like Cloud Run, GKE, and SpannerDB. I am deeply involved in the entire SDLC, from solution design to production support.",
      "resumePoints": [
        "Developing an integration platform to handle complex business objects to and from PLM software APIs and other in-house applications, making them available in a standardized format for over 10+ downstream systems.",
        "This involves creating a configurable, no-code workflow to streamline and automate the process."
      ],
      "skillsUsed": [
        { "category": "Cloud & DevOps", "skills": ["Google Cloud Platform (GCP)", "GKE"] },
        { "category": "Databases", "skills": ["SpannerDB"] },
        { "category": "Languages & Frameworks", "skills": ["Python", "FastAPI"] },
        { "category": "Concepts", "skills": ["Enterprise Integration Patterns", "End-to-End SDLC Ownership"] }
      ]
    },
    {
      "id": "interest-current-2024",
      "type": "personal_interest",
      "heading": "Hobbies & Interests",
      "startDate": "2024-03-01",
      "endDate": null,
      "narrative": "Throughout my journey, I've balanced my deep focus in technology with a love for creative outlets. I'm an active part of the company culture and a keen badminton player, having won several internal tournaments. I'm also an avid anime fan and a proficient cook. My thinking is often shaped by authors like Yuval Noah Harari and Paulo Coelho, whose works encourage looking at the bigger pictureâ€”a principle I apply to both my life and my work in system architecture."
    },
    {
      "id": "project-applibot-2023",
      "type": "project",
      "heading": "Personal Project: applibot.io",
      "startDate": "2023-01-01",
      "endDate": "2024-01-01",
      "narrative": "Fueled by my experience across diverse teams and my ambition as an aspiring system architect, I sought a role with greater end-to-end ownership. To aid my job search, I built `applibot.io`, a RAG application to automate job applications. The tech stack included LanceDB, PostgreSQL, FastAPI, and I leveraged LangChain alongside OpenAI models as the primary LLM framework.",
      "skillsUsed": [
        { "category": "AI/ML", "skills": ["RAG Architecture", "LLMs", "LangChain", "Vector Databases"] },
        { "category": "Backend", "skills": ["FastAPI"] },
        { "category": "Concepts", "skills": ["Full-Stack Development", "Product Ideation"] }
      ]
    },
    {
      "id": "milestone-leetcode-2023",
      "type": "personal_milestone",
      "heading": "LeetCode 50-Day Challenge",
      "startDate": "2023-10-01",
      "endDate": "2023-11-20",
      "narrative": "To continuously sharpen my foundational skills, I dedicated time to competitive programming. This preparation culminated in a 50-day challenge on LeetCode, where I earned a badge awarded to the top 6.9% of global participants."
    },
    {
      "id": "cert-system-design-2023",
      "type": "certification",
      "heading": "System Design",
      "organization": { "name": "Udemy" },
      "startDate": "2023-09-01",
      "certificateURL": "https://www.udemy.com/certificate/UC-a6688b24-e5c2-48e2-9c10-231f972eae68/"
    },
    {
      "id": "cert-dsa-2023",
      "type": "certification",
      "heading": "Data Structures & Algorithms",
      "organization": { "name": "Udemy" },
      "startDate": "2023-08-01",
      "certificateURL": "https://www.udemy.com/certificate/UC-e7d015c6-9477-45e0-9e0c-8d1863d038f6/"
    },
    {
      "id": "exp-jio-2021",
      "type": "experience",
      "heading": "Software Engineer II",
      "organization": { "name": "Jio Platforms Private Limited" },
      "role": "Software Engineer II",
      "location": "Bengaluru, India",
      "startDate": "2021-09-01",
      "endDate": "2024-03-01",
      "narrative": "I transitioned to the AI-Center of Excellence (AI-COE) team at Jio. My primary contribution was engineering a comprehensive Knowledge Graph platform built on ArangoDB, using Redis for caching to enhance query performance. The platform's microservices architecture was built on gRPC and Protocol Buffers. As the team grew, my role evolved to include mentoring and training new members. Beyond leadership, I also spearheaded the performance monitoring, scaling, and refinement of our Knowledge Graph services, ensuring high reliability and efficiency. The entire platform was deployed on Kubernetes using CI/CD pipelines I built on Azure DevOps.",
      "resumePoints": [
        "Engineered a comprehensive Knowledge-graph platform, encompassing micro-services like Schema, Data, and Search, to facilitate the semantic storage and retrieval of domain knowledge, enhancing data accessibility and interoperability.",
        "Spearheaded the performance monitoring, scaling, and refinement of Knowledge Graph services, ensuring optimal scalability for Big Data ingestion and retrieval, and enhancing service reliability and efficiency.",
        "Provided mentorship on best practices and maintainability within the AICOE's AI platform, fostering a culture of knowledge sharing and continuous improvement within the team."
      ],
      "skillsUsed": [
        { "category": "System Design", "skills": ["System Design & Architecture", "gRPC"] },
        { "category": "Databases & Caching", "skills": ["ArangoDB", "Redis"] },
        { "category": "DevOps & MLOps", "skills": ["Kubernetes", "Azure DevOps", "MLOps"] },
        { "category": "Soft Skills", "skills": ["Technical Leadership & Mentorship"] }
      ]
    },
    {
      "id": "cert-protobuf-2021",
      "type": "certification",
      "heading": "Protocol Buffers",
      "organization": { "name": "Udemy" },
      "startDate": "2021-11-01",
      "certificateURL": "https://www.udemy.com/certificate/UC-1dd3f3c2-d8ad-46b5-9a09-801f26cf0df6/"
    },
    {
      "id": "cert-ai-2021",
      "type": "certification",
      "heading": "AI for Everyone",
      "organization": { "name": "Coursera" },
      "startDate": "2021-10-01",
      "certificateURL": "https://www.coursera.org/account/accomplishments/certificate/JMQWSQBKDSZC"
    },
    {
      "id": "exp-ajio-2019",
      "type": "experience",
      "heading": "DevOps Engineer",
      "organization": { "name": "Ajio" },
      "role": "DevOps Engineer",
      "location": "Bengaluru, India",
      "startDate": "2019-09-01",
      "endDate": "2021-09-01",
      "narrative": "I moved to Ajio, where I founded and led the Tools & Automation team. My mission was to implement strategic automation solutions that would streamline workflows. Before building the large-scale ELK pipeline, my initial focus was on operational stability, where I implemented Prometheus for monitoring. My team's flagship project became a centralized visibility platform built on ELK and Kafka clusters, designed to pinpoint performance bottlenecks in real-time. We scaled this platform to support over 16 microservices, processing over 7 billion log records daily. All deployments and configuration changes were managed using Ansible.",
      "resumePoints": [
        "Engineered and deployed multiple robust clusters designed for extensive log aggregation, capable of processing over 7 billion records daily, alongside conducting comprehensive load testing for the in-house cloud infrastructure platform: JAWS.",
        "Oversaw and optimized the scalability of ELK and Kafka clusters to accommodate the diverse operational needs across various Jio business units, ensuring seamless data flow and reduced system latency.",
        "Founded and led the Tools & Automation team at Ajio, implementing strategic automation solutions to streamline workflows and eliminate redundant tasks across multiple departments, enhancing overall operational efficiency."
      ],
      "skillsUsed": [
        { "category": "Data Engineering", "skills": ["ELK Stack Administration", "Apache Kafka Management", "Large-Scale Data Architecture"] },
        { "category": "DevOps & Monitoring", "skills": ["Prometheus", "Ansible", "Microservices Monitoring"] },
        { "category": "Concepts", "skills": ["System Scalability & Performance Tuning"] },
        { "category": "Soft Skills", "skills": ["Team Leadership"] }
      ]
    },
    {
      "id": "exp-deepcompute-2017",
      "type": "experience",
      "heading": "Associate Software Engineer",
      "organization": { "name": "Deepcompute LLC" },
      "role": "Associate Software Engineer",
      "location": "Bengaluru, India",
      "startDate": "2017-08-01",
      "endDate": "2019-09-01",
      "narrative": "My professional career began at Deepcompute, a dynamic startup. I transitioned from Java to Python and was tasked with building and supporting critical internal tools. I actively collaborated with cross-functional teams to develop and enhance several open-source libraries and modules like `logagg`, `basescript`, and `deeputil`. My primary responsibilities revolved around the data pipeline, which involved ingesting large volumes of JSON data and administering the supporting infrastructure, including MongoDB, InfluxDB, and NSQ. I also played a pivotal role in shaping our engineering practices by facilitating deployments using Docker and Travis CI.",
      "resumePoints": [
        "Collaborated with cross-functional teams to develop and enhance open-source libraries and modules such as logagg, basescript, deeputil, contributing to the creation of versatile and reusable software components.",
        "Played a pivotal role in application development and facilitated teams in managing deployments and logs, establishing and enforcing stringent benchmarks for code quality to ensure the delivery of robust and efficient software solutions."
      ],
      "skillsUsed": [
        { "category": "Languages", "skills": ["Python"] },
        { "category": "Data Engineering", "skills": ["Data Pipelines", "NSQ", "MongoDB", "InfluxDB"] },
        { "category": "DevOps", "skills": ["Docker", "CI/CD Pipeline Management", "Bash Scripting"] },
        { "category": "Tools & Workflows", "skills": ["Git Workflows", "Linux System Administration"] },
        { "category": "Community", "skills": ["Open-Source Contribution"] }
      ]
    },
    {
      "id": "interest-stickers-2018",
      "type": "personal_interest",
      "heading": "Creative Outlet: Sticker Design",
      "startDate": "2018-08-01",
      "endDate": "2019-09-01",
      "narrative": "After my first year at Deepcompute, I also briefly ventured into creative design, making and selling stickers."
    },
    {
      "id": "edu-mit-2013",
      "type": "education",
      "heading": "Bachelor of Technology, Computer Science",
      "organization": { "name": "Mallabhum Institute of Technology" },
      "role": "Undergraduate Student",
      "startDate": "2013-08-01",
      "endDate": "2017-05-31",
      "narrative": "My college years were a period of immense learning, where I was formally introduced to the core principles that govern the digital world. The curriculum covered a wide spectrum of essential topics, including 16-bit microprocessors, Computer Architecture, the Linux kernel, and intricate Networks and protocols. This comprehensive education provided me with a robust understanding of how software and hardware interact.",
      "skillsUsed": [
        { "category": "Core CS", "skills": ["Data Structures", "Algorithms", "OS", "Computer Architecture", "Networking", "Linux kernel basics"] },
        { "category": "Soft Skills", "skills": ["Teamwork", "Collaboration"] }
      ]
    },
    {
      "id": "interest-volleyball-2013",
      "type": "personal_interest",
      "heading": "Volleyball",
      "startDate": "2013-08-01",
      "endDate": "2017-05-31",
      "narrative": "Outside of academics, I also discovered a passion for volleyball, where I honed my skills in teamwork, strategy, and coordination, eventually becoming a proficient player."
    },
    {
      "id": "edu-dav-2011",
      "type": "education",
      "heading": "High School",
      "organization": { "name": "D.A.V Public School" },
      "role": "Student",
      "startDate": "2011-04-01",
      "endDate": "2013-03-31",
      "narrative": "This period was instrumental in broadening my technical horizons, as I learned additional programming languages, including C++ and PHP. Beyond the curriculum, I was captivated by the burgeoning smartphone ecosystem and spent countless hours on the XDA Developers forums. This hands-on exploration involved experimenting with custom firmware, software modifications, and troubleshooting complex technical issues, which sharpened my practical problem-solving skills.",
      "skillsUsed": [
        { "category": "Programming", "skills": ["C++", "PHP", "Advanced programming concepts"] },
        { "category": "Concepts", "skills": ["Mobile operating system fundamentals"] },
        { "category": "Soft Skills", "skills": ["Practical troubleshooting", "Self-directed learning"] }
      ]
    },
    {
      "id": "interest-xda-2011",
      "type": "personal_interest",
      "heading": "Hobby: XDA Developers Forums",
      "startDate": "2011-04-01",
      "endDate": "2013-03-31",
      "narrative": "I was captivated by the burgeoning smartphone ecosystem and spent countless hours on the XDA Developers forums. This hands-on exploration involved experimenting with custom firmware, software modifications, and troubleshooting complex technical issues, which sharpened my practical problem-solving skills. It was during this time that I solidified my ambition to pursue Computer Science as a professional career, with my passion for football serving as a cherished Plan B."
    },
    {
      "id": "edu-denobili-2000",
      "type": "education",
      "heading": "School",
      "organization": { "name": "De Nobili School" },
      "role": "Student",
      "startDate": "2000-04-01",
      "endDate": "2011-03-31",
      "narrative": "My academic journey began at De Nobili School, where my natural curiosity for technology first took root. I was deeply intrigued by the dawn of the digital age, particularly the internet and its underlying mechanisms. This fascination led me to enroll in Computer Science classes, which provided my first formal introduction to the world of programming through the Java language.",
      "skillsUsed": [
        { "category": "Programming", "skills": ["Introductory Java", "Foundational programming logic"] },
        { "category": "Soft Skills", "skills": ["Analytical thinking"] }
      ]
    }
  ]
}